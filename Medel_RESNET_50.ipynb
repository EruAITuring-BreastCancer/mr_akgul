{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ergul13/mr_akgul/blob/main/Medel_RESNET_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. ORTAM KURULUMU VE BAĞLANTI ---\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Drive Bağla\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Cihaz Kontrolü (GPU Şart)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Kullanılan Cihaz: {device}\")\n",
        "if device.type != 'cuda':\n",
        "    print(\"UYARI: GPU aktif değil! Eğitim çok yavaş olur. Çalışma Zamanı > Türü Değiştir > T4 GPU seç.\")\n",
        "\n",
        "# --- 2. VERİ SETİNİ YÜKLE ---\n",
        "csv_path = '/content/drive/MyDrive/FINAL_ALL_DATA.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Sınıf Dağılımını Hatırlayalım\n",
        "print(\"\\n--- EĞİTİLECEK VERİ SETİ ---\")\n",
        "print(df['label'].value_counts().sort_index())\n",
        "\n",
        "# Class Weights (Sınıf Ağırlıkları) Hesaplama\n",
        "# Az olan sınıfa yüksek ağırlık vereceğiz.\n",
        "class_counts = df['label'].value_counts().sort_index()\n",
        "total_samples = len(df)\n",
        "num_classes = len(class_counts)\n",
        "\n",
        "# Formül: Toplam / (Sınıf Sayısı * Sınıfın Frekansı)\n",
        "class_weights = total_samples / (num_classes * class_counts)\n",
        "\n",
        "print(\"\\n--- HESAPLANAN SINIF AĞIRLIKLARI (Class Weights) ---\")\n",
        "print(\"(Model bu katsayıları kullanarak azınlık sınıflarına odaklanacak)\")\n",
        "print(class_weights)\n",
        "\n",
        "# Bu ağırlıkları tensöre çevirip saklayalım, eğitimde kullanacağız.\n",
        "weights_tensor = torch.tensor(class_weights.values, dtype=torch.float).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NghjiNSuGllm",
        "outputId": "f8cc97df-b722-42f1-c273-37927ad518b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kullanılan Cihaz: cuda\n",
            "\n",
            "--- EĞİTİLECEK VERİ SETİ ---\n",
            "label\n",
            "1    53615\n",
            "2      243\n",
            "4       43\n",
            "5     1215\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- HESAPLANAN SINIF AĞIRLIKLARI (Class Weights) ---\n",
            "(Model bu katsayıları kullanarak azınlık sınıflarına odaklanacak)\n",
            "label\n",
            "1      0.256999\n",
            "2     56.703704\n",
            "4    320.441860\n",
            "5     11.340741\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# --- 1. ETİKET HARİTALAMA (MAPPING) ---\n",
        "# PyTorch sınıf indekslerinin 0'dan başlamasını ister.\n",
        "# Mevcut: 1, 2, 4, 5 -> Hedef: 0, 1, 2, 3\n",
        "label_map = {\n",
        "    1: 0, # Normal\n",
        "    2: 1, # İyi Huylu\n",
        "    4: 2, # Şüpheli (Azınlık)\n",
        "    5: 3  # Kanser\n",
        "}\n",
        "\n",
        "# Veri setine yeni 'target' sütununu ekleyelim\n",
        "df['target'] = df['label'].map(label_map)\n",
        "\n",
        "print(\"Etiketler PyTorch formatına (0-3) dönüştürüldü.\")\n",
        "\n",
        "# --- 2. KATMANLI BÖLME (STRATIFIED SPLIT) ---\n",
        "# Önce Train (%80) ve Kalan (%20) olarak bölüyoruz\n",
        "# stratify=df['target'] sayesinde her sınıftan eşit oranda alıyor.\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df['target'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Kalan %20'yi de Validation (%10) ve Test (%10) olarak ikiye bölüyoruz\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df['target'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- 3. KAYIT (SAVE) ---\n",
        "# Bölünen dosyaları Drive'a kaydediyoruz ki sabit kalsınlar.\n",
        "save_dir = '/content/drive/MyDrive/SPLIT_DATA'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "train_df.to_csv(f'{save_dir}/train.csv', index=False)\n",
        "val_df.to_csv(f'{save_dir}/val.csv', index=False)\n",
        "test_df.to_csv(f'{save_dir}/test.csv', index=False)\n",
        "\n",
        "print(\"\\n--- BÖLME İŞLEMİ TAMAMLANDI VE KAYDEDİLDİ ---\")\n",
        "print(f\"Kayıt Yeri: {save_dir}\")\n",
        "print(f\"Eğitim (Train) Seti  : {len(train_df)} veri\")\n",
        "print(f\"Doğrulama (Val) Seti : {len(val_df)} veri\")\n",
        "print(f\"Test Seti            : {len(test_df)} veri\")\n",
        "\n",
        "# Kritik Kontrol: Sınıf 4 (En az olan) her sete dağılmış mı?\n",
        "print(\"\\n--- KRİTİK KONTROL: Sınıf 4 (Şüpheli) Dağılımı ---\")\n",
        "print(f\"Train içinde Sınıf 4 Sayısı: {len(train_df[train_df['label']==4])}\")\n",
        "print(f\"Val   içinde Sınıf 4 Sayısı: {len(val_df[val_df['label']==4])}\")\n",
        "print(f\"Test  içinde Sınıf 4 Sayısı: {len(test_df[test_df['label']==4])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGPgRwnCIeCi",
        "outputId": "b3f9a7da-c490-47e7-8834-a505409faee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiketler PyTorch formatına (0-3) dönüştürüldü.\n",
            "\n",
            "--- BÖLME İŞLEMİ TAMAMLANDI VE KAYDEDİLDİ ---\n",
            "Kayıt Yeri: /content/drive/MyDrive/SPLIT_DATA\n",
            "Eğitim (Train) Seti  : 44092 veri\n",
            "Doğrulama (Val) Seti : 5512 veri\n",
            "Test Seti            : 5512 veri\n",
            "\n",
            "--- KRİTİK KONTROL: Sınıf 4 (Şüpheli) Dağılımı ---\n",
            "Train içinde Sınıf 4 Sayısı: 35\n",
            "Val   içinde Sınıf 4 Sayısı: 4\n",
            "Test  içinde Sınıf 4 Sayısı: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# --- 1. DATASET SINIFI (Veri Okuyucu) ---\n",
        "class BreastCancerDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        \"\"\"\n",
        "        csv_file: 'train.csv', 'val.csv' veya 'test.csv' yolu\n",
        "        transform: Uygulanacak görüntü dönüşümleri (Augmentation)\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Resim yolunu al\n",
        "        img_path = self.data.iloc[idx]['path']\n",
        "\n",
        "        # 2. Etiketi al (0, 1, 2, 3)\n",
        "        label = int(self.data.iloc[idx]['target'])\n",
        "\n",
        "        # 3. Resmi aç (RGB formatında)\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            # Eğer resim bozuksa siyah bir resim oluştur (Kodun patlamaması için)\n",
        "            print(f\"Hata: Resim okunamadı {img_path}\")\n",
        "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "\n",
        "        # 4. Dönüşümleri uygula (Resize, Augmentation, Tensor)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- 2. DÖNÜŞÜMLER (TRANSFORMS) ---\n",
        "# Modelin gözü: Resimleri nasıl görecek?\n",
        "\n",
        "# Eğitim Dönüşümleri (Ağır Augmentation - Veri Çoğaltma)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),        # Boyut sabitleme\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # %50 ihtimalle yatay çevir\n",
        "    transforms.RandomVerticalFlip(p=0.5),   # %50 ihtimalle dikey çevir\n",
        "    transforms.RandomRotation(15),        # 15 derece döndür\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Işıkla oyna\n",
        "    transforms.ToTensor(),                # Sayısal Tensöre çevir\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Renk normalizasyonu\n",
        "])\n",
        "\n",
        "# Test/Validation Dönüşümleri (Sade - Sadece Boyutlandırma)\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# --- 3. TEST (Kod çalışıyor mu?) ---\n",
        "# Sadece deneme amaçlı train setinden bir parça yüklüyoruz\n",
        "try:\n",
        "    test_ds = BreastCancerDataset(\n",
        "        csv_file='/content/drive/MyDrive/SPLIT_DATA/train.csv',\n",
        "        transform=train_transforms\n",
        "    )\n",
        "\n",
        "    img, lbl = test_ds[0] # İlk resmi al\n",
        "    print(\"--- DATASET TEST RAPORU ---\")\n",
        "    print(f\"Örnek Resim Boyutu (Tensor): {img.shape}\")\n",
        "    print(f\"Örnek Etiket: {lbl}\")\n",
        "    print(\"Sistem başarıyla kuruldu. Resimler okunabiliyor.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"BİR HATA OLUŞTU: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zBUqMhXJgRB",
        "outputId": "f82fbc2f-1a09-4533-8c5b-6bb38ef2a2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DATASET TEST RAPORU ---\n",
            "Örnek Resim Boyutu (Tensor): torch.Size([3, 224, 224])\n",
            "Örnek Etiket: 0\n",
            "Sistem başarıyla kuruldu. Resimler okunabiliyor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. AĞIRLIKLI ÖRNEKLEYİCİ (WEIGHTED SAMPLER) HAZIRLIĞI ---\n",
        "\n",
        "# Train setindeki tüm etiketleri bir listeye alalım\n",
        "train_targets = train_df['target'].tolist()\n",
        "\n",
        "# Daha önce hesapladığımız sınıf ağırlıklarını (class_weights) hatırlayalım\n",
        "# label 1 -> 0.25 (Çok var, az al)\n",
        "# label 4 -> 320.4 (Çok az, çok al)\n",
        "# Dikkat: class_weights Series objesiydi, bunu bir sözlüğe (dict) çevirelim ki erişimi kolay olsun.\n",
        "# label_map ile dönüşüm yapmıştık (1->0, 2->1, 4->2, 5->3). Ağırlıkları da buna uyduralım.\n",
        "\n",
        "# Orijinal etiketlere göre ağırlıklar:\n",
        "weight_dict = class_weights.to_dict()\n",
        "\n",
        "# PyTorch etiketlerine (0,1,2,3) göre ağırlık haritası:\n",
        "# label_map'in tersini kullanacağız veya manuel eşleştireceğiz.\n",
        "# label_map = {1:0, 2:1, 4:2, 5:3}\n",
        "mapped_weights = {\n",
        "    0: weight_dict[1],   # Class 1 (Normal)\n",
        "    1: weight_dict[2],   # Class 2 (İyi Huylu)\n",
        "    2: weight_dict[4],   # Class 4 (Şüpheli - En Yüksek Ağırlık)\n",
        "    3: weight_dict[5]    # Class 5 (Kanser)\n",
        "}\n",
        "\n",
        "print(\"PyTorch Sınıf Ağırlıkları:\", mapped_weights)\n",
        "\n",
        "# Her bir eğitim örneği için (44092 tane) bir ağırlık değeri atayacağız\n",
        "samples_weights = [mapped_weights[t] for t in train_targets]\n",
        "\n",
        "# Sampler Objesini Oluştur\n",
        "# replacement=True: Bir resim aynı epochta birden fazla kez çekilebilir (Veri çoğaltma etkisi yaratır)\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=samples_weights,\n",
        "    num_samples=len(samples_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# --- 2. DATALOADERS (VERİ YÜKLEYİCİLER) ---\n",
        "\n",
        "# Batch Size: GPU belleğine göre ayarlanır. T4 için 32 veya 64 uygundur.\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Train Loader (Sampler ile)\n",
        "# shuffle=False olmak ZORUNDA çünkü sampler zaten karıştırıyor.\n",
        "train_dataset = BreastCancerDataset(f'{save_dir}/train.csv', transform=train_transforms)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=sampler,  # Kritik nokta burası!\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# Val Loader (Sıradan, karıştırmaya gerek yok)\n",
        "val_dataset = BreastCancerDataset(f'{save_dir}/val.csv', transform=val_transforms)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# Test Loader\n",
        "test_dataset = BreastCancerDataset(f'{save_dir}/test.csv', transform=val_transforms)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(\"\\n--- DATALOADER HAZIR ---\")\n",
        "print(f\"Train Loader: {len(train_loader)} batch (Her batch'te {BATCH_SIZE} resim)\")\n",
        "print(\"Sınıf 4 artık eğitim sırasında diğerleriyle eşit oranda görünecek.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-335ECJ_JxnM",
        "outputId": "70cc15d7-1473-48bb-cb35-f6b3d359c748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Sınıf Ağırlıkları: {0: 0.256998974167677, 1: 56.7037037037037, 2: 320.4418604651163, 3: 11.34074074074074}\n",
            "\n",
            "--- DATALOADER HAZIR ---\n",
            "Train Loader: 1378 batch (Her batch'te 32 resim)\n",
            "Sınıf 4 artık eğitim sırasında diğerleriyle eşit oranda görünecek.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESNET-50**"
      ],
      "metadata": {
        "id": "In92HpwCKgbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- 1. MODEL MİMARİSİ (ResNet50) ---\n",
        "print(\"ResNet50 modeli indiriliyor ve yapılandırılıyor...\")\n",
        "\n",
        "# Önceden eğitilmiş ağırlıkları kullan\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modelin son katmanını değiştir (4 Sınıf için)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)\n",
        "\n",
        "# Modeli GPU'ya taşı\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model GPU'ya taşındı: {next(model.parameters()).device}\")\n",
        "\n",
        "# --- 2. HATA FONKSİYONU (LOSS FUNCTION) ---\n",
        "# Sınıf ağırlıklarını (weights_tensor) kullanıyoruz\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
        "\n",
        "# --- 3. OPTİMİZASYON (OPTIMIZER) ---\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# --- 4. ÖĞRENME HIZI PLANLAYICI (SCHEDULER) ---\n",
        "# verbose parametresini kaldırdık\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.1,\n",
        "    patience=3\n",
        ")\n",
        "\n",
        "print(\"Model, Loss Fonksiyonu ve Optimizer başarıyla hazırlandı.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plNN5h3lKHbP",
        "outputId": "5ff0a581-94b8-45de-cb87-9022187a26d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet50 modeli indiriliyor ve yapılandırılıyor...\n",
            "Model GPU'ya taşındı: cuda:0\n",
            "Model, Loss Fonksiyonu ve Optimizer başarıyla hazırlandı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- AYARLAR ---\n",
        "EPOCHS = 15  # 15 tur dönecek (İstersen artırabilirsin)\n",
        "best_val_loss = float('inf') # En iyi kaybı takip etmek için\n",
        "save_path = '/content/drive/MyDrive/best_breast_cancer_model.pth'\n",
        "\n",
        "history = {\n",
        "    'train_loss': [], 'train_acc': [],\n",
        "    'val_loss': [], 'val_acc': []\n",
        "}\n",
        "\n",
        "print(f\"Eğitim başlıyor... Hedef: {EPOCHS} Epoch\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    # --- 1. EĞİTİM MODU (TRAIN) ---\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    # Tqdm ile ilerleme çubuğu\n",
        "    for inputs, labels in tqdm(train_loader, desc=\"Eğitiliyor\"):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Sıfırla -> İleri -> Hata Hesapla -> Geri -> Güncelle\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels) # Ağırlıklı Loss burada devreye giriyor\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # İstatistikler\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
        "\n",
        "    # --- 2. DOĞRULAMA MODU (VALIDATION) ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "\n",
        "    with torch.no_grad(): # Validation'da gradyan hesaplanmaz (Hız ve Hafıza)\n",
        "        for inputs, labels in tqdm(val_loader, desc=\"Doğrulanıyor\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    val_epoch_loss = val_loss / len(val_dataset)\n",
        "    val_epoch_acc = val_corrects.double() / len(val_dataset)\n",
        "\n",
        "    # --- 3. RAPORLAMA VE KAYIT ---\n",
        "    print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "    print(f\"Val   Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}\")\n",
        "\n",
        "    # Geçmişi kaydet\n",
        "    history['train_loss'].append(epoch_loss)\n",
        "    history['train_acc'].append(epoch_acc.item())\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc.item())\n",
        "\n",
        "    # Scheduler Adımı (Validation Loss düşmüyorsa öğrenme hızını kıs)\n",
        "    scheduler.step(val_epoch_loss)\n",
        "\n",
        "    # En iyi modeli kaydet (Checkpoint)\n",
        "    if val_epoch_loss < best_val_loss:\n",
        "        print(f\"✔ İyileşme var! ({best_val_loss:.4f} -> {val_epoch_loss:.4f}). Model kaydediliyor...\")\n",
        "        best_val_loss = val_epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "    else:\n",
        "        print(\"Model bu turda gelişmedi.\")\n",
        "\n",
        "# --- BİTİŞ ---\n",
        "total_time = time.time() - start_time\n",
        "print(\"-\" * 60)\n",
        "print(f\"Eğitim tamamlandı. Toplam Süre: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
        "print(f\"En iyi Validation Loss: {best_val_loss:.4f}\")\n",
        "print(f\"Model Kayıt Yeri: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RmBUfjbXKZsD",
        "outputId": "6c81ce76-5f3d-4062-db15-03e06a34e764"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eğitim başlıyor... Hedef: 15 Epoch\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eğitiliyor: 100%|██████████| 1378/1378 [25:55<00:00,  1.13s/it]\n",
            "Doğrulanıyor: 100%|██████████| 173/173 [00:26<00:00,  6.58it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0990 Acc: 0.6845\n",
            "Val   Loss: 2.8306 Acc: 0.0247\n",
            "✔ İyileşme var! (inf -> 2.8306). Model kaydediliyor...\n",
            "\n",
            "Epoch 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eğitiliyor:  42%|████▏     | 573/1378 [10:42<14:36,  1.09s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merhaba ve yeniden selamlar herkese"
      ],
      "metadata": {
        "id": "95M9uLxlLQFK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1ExAFibXzZktjO8PBkcHTcZLGoHXcK46S",
      "authorship_tag": "ABX9TyM5Bi5qodv+oVaUTO0QAJtq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}