{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ergul13/mr_akgul/blob/main/%C3%A7oklu_s%C4%B1n%C4%B1fland%C4%B1rma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Drive Bağlantısı\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 2. Ana Dizin ve CSV Yolları\n",
        "base_dir = '/content/drive/MyDrive/Meme_Kanseri_Proje_Verileri'\n",
        "train_csv = os.path.join(base_dir, 'SPLIT_DATA', 'train.csv')\n",
        "val_csv = os.path.join(base_dir, 'SPLIT_DATA', 'val.csv')\n",
        "test_csv = os.path.join(base_dir, 'SPLIT_DATA', 'test.csv')\n",
        "\n",
        "# 3. Verileri Yükleme ve Yol Düzeltme Fonksiyonu\n",
        "def load_and_fix_paths(csv_path):\n",
        "    if not os.path.exists(csv_path):\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if 'path' in df.columns:\n",
        "        # Eski yolları yeni klasör yapısına yönlendir\n",
        "        df['path'] = df['path'].str.replace(\n",
        "            '/content/drive/MyDrive/',\n",
        "            '/content/drive/MyDrive/Meme_Kanseri_Proje_Verileri/',\n",
        "            regex=False\n",
        "        )\n",
        "    return df\n",
        "\n",
        "df_train = load_and_fix_paths(train_csv)\n",
        "df_val = load_and_fix_paths(val_csv)\n",
        "df_test = load_and_fix_paths(test_csv)\n",
        "\n",
        "print(f\"Veri Setleri Yüklendi:\")\n",
        "print(f\"Eğitim: {len(df_train)} satır\")\n",
        "print(f\"Doğrulama: {len(df_val)} satır\")\n",
        "print(f\"Test: {len(df_test)} satır\")\n",
        "print(f\"Toplam görüntü sayısı: {len(df_train) + len(df_val)+ len(df_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCwZ3jNw3iLe",
        "outputId": "8168a164-a58a-4846-c437-fec79595ffe0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Veri Setleri Yüklendi:\n",
            "Eğitim: 44092 satır\n",
            "Doğrulama: 5512 satır\n",
            "Test: 5512 satır\n",
            "Toplam görüntü sayısı: 55116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sınıf Dağılım Tablosu Oluşturma\n",
        "def create_distribution_table(df_train, df_val, df_test):\n",
        "    # Tüm setlerdeki benzersiz sınıfları bul\n",
        "    all_classes = sorted(df_train['label'].unique())\n",
        "\n",
        "    stats = []\n",
        "    for cls in all_classes:\n",
        "        train_c = len(df_train[df_train['label'] == cls])\n",
        "        val_c = len(df_val[df_val['label'] == cls]) if not df_val.empty else 0\n",
        "        test_c = len(df_test[df_test['label'] == cls])\n",
        "        total = train_c + val_c + test_c\n",
        "\n",
        "        # Eğitim seti içindeki oranı\n",
        "        ratio = (train_c / len(df_train) * 100) if len(df_train) > 0 else 0\n",
        "\n",
        "        stats.append({\n",
        "            'BI-RADS Sınıfı': cls,\n",
        "            'Eğitim (Adet)': train_c,\n",
        "            'Doğrulama (Adet)': val_c,\n",
        "            'Test (Adet)': test_c,\n",
        "            'Toplam': total,\n",
        "            'Eğitim Payı (%)': f\"%{ratio:.2f}\"\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(stats)\n",
        "\n",
        "stat_table = create_distribution_table(df_train, df_val, df_test)\n",
        "\n",
        "print(\"VERİ SETİ SINIF DAĞILIM İSTATİSTİKLERİ\")\n",
        "print(\"-\" * 80)\n",
        "print(stat_table.to_string(index=False))\n",
        "print(\"-\" * 80)\n",
        "print(f\"\\nToplam Görüntü Sayısı: {stat_table['Toplam'].sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "484fvF0b3ihX",
        "outputId": "8a543004-b19b-4e65-9f97-f1ea275ea70b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERİ SETİ SINIF DAĞILIM İSTATİSTİKLERİ\n",
            "--------------------------------------------------------------------------------\n",
            " BI-RADS Sınıfı  Eğitim (Adet)  Doğrulama (Adet)  Test (Adet)  Toplam Eğitim Payı (%)\n",
            "              1          42891              5362         5362   53615          %97.28\n",
            "              2            194                24           25     243           %0.44\n",
            "              4             35                 4            4      43           %0.08\n",
            "              5            972               122          121    1215           %2.20\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Toplam Görüntü Sayısı: 55116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.utils import resample\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. TEMEL AYARLAR VE VERİ YÜKLEME\n",
        "base_dir = '/content/drive/MyDrive/Meme_Kanseri_Proje_Verileri'\n",
        "train_csv = os.path.join(base_dir, 'SPLIT_DATA', 'train.csv')\n",
        "val_csv = os.path.join(base_dir, 'SPLIT_DATA', 'val.csv')\n",
        "\n",
        "# Yükleme Fonksiyonu\n",
        "def load_and_fix(path):\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_csv(path)\n",
        "        if 'path' in df.columns:\n",
        "            # Yolları güncelle\n",
        "            df['path'] = df['path'].str.replace(\n",
        "                '/content/drive/MyDrive/',\n",
        "                '/content/drive/MyDrive/Meme_Kanseri_Proje_Verileri/',\n",
        "                regex=False\n",
        "            )\n",
        "        return df\n",
        "    return pd.DataFrame()\n",
        "\n",
        "df_train = load_and_fix(train_csv)\n",
        "df_val = load_and_fix(val_csv)\n",
        "\n",
        "# 2. MODEL 3 (BI-RADS 4) VERİ SETİNİ HAZIRLAMA (EKSİK OLAN KISIM)\n",
        "def prepare_model3_data(df, target_class=4):\n",
        "    # Pozitif Sınıf (4)\n",
        "    df_pos = df[df['label'] == target_class].copy()\n",
        "\n",
        "    # Augmentation İşaretlemesi (4 Kat)\n",
        "    aug_data = []\n",
        "    for _, row in df_pos.iterrows():\n",
        "        aug_data.append({'path': row['path'], 'binary_label': 1, 'aug_type': 'original'})\n",
        "        aug_data.append({'path': row['path'], 'binary_label': 1, 'aug_type': 'rot90'})\n",
        "        aug_data.append({'path': row['path'], 'binary_label': 1, 'aug_type': 'rot180'})\n",
        "        aug_data.append({'path': row['path'], 'binary_label': 1, 'aug_type': 'rot270'})\n",
        "    df_pos_aug = pd.DataFrame(aug_data)\n",
        "\n",
        "    # Negatif Sınıf (Diğerleri)\n",
        "    df_neg = df[df['label'] != target_class].copy()\n",
        "    n_pos = len(df_pos_aug)\n",
        "    n_neg = min(len(df_neg), n_pos * 2) # 1:2 Oran\n",
        "\n",
        "    if n_neg > 0:\n",
        "        df_neg_sampled = resample(df_neg, n_samples=n_neg, replace=False, random_state=42)\n",
        "        neg_data = [{'path': row['path'], 'binary_label': 0, 'aug_type': 'original'} for _, row in df_neg_sampled.iterrows()]\n",
        "        return pd.concat([df_pos_aug, pd.DataFrame(neg_data)]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    return df_pos_aug\n",
        "\n",
        "# Değişkenleri Oluştur\n",
        "df_train_m3 = prepare_model3_data(df_train)\n",
        "\n",
        "# Validation Hazırlığı\n",
        "val_list = []\n",
        "if not df_val.empty:\n",
        "    for _, row in df_val.iterrows():\n",
        "        label = 1 if row['label'] == 4 else 0\n",
        "        val_list.append({'path': row['path'], 'binary_label': label, 'aug_type': 'original'})\n",
        "    df_val_m3 = pd.DataFrame(val_list)\n",
        "else:\n",
        "    df_val_m3 = pd.DataFrame()\n",
        "\n",
        "print(f\"Model 3 Eğitim Verisi: {len(df_train_m3)} adet\")\n",
        "print(f\"Model 3 Doğrulama Verisi: {len(df_val_m3)} adet\")\n",
        "\n",
        "# 3. PARALEL KOPYALAMA (HIZLANDIRILMIŞ)\n",
        "local_dir = '/content/local_data'\n",
        "if os.path.exists(local_dir): shutil.rmtree(local_dir)\n",
        "os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "# Kopyalanacak benzersiz dosyalar\n",
        "files_to_copy = list(set(df_train_m3['path'].tolist() + df_val_m3['path'].tolist()))\n",
        "path_map = {}\n",
        "\n",
        "print(f\"\\n{len(files_to_copy)} dosya paralel olarak kopyalanıyor...\")\n",
        "\n",
        "def copy_worker(src):\n",
        "    try:\n",
        "        if os.path.exists(src):\n",
        "            dst = os.path.join(local_dir, os.path.basename(src))\n",
        "            shutil.copy(src, dst)\n",
        "            return src, dst\n",
        "    except:\n",
        "        return None, None\n",
        "    return None, None\n",
        "\n",
        "# 16 Thread ile kopyala\n",
        "with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "    results = list(tqdm(executor.map(copy_worker, files_to_copy), total=len(files_to_copy)))\n",
        "\n",
        "# Haritalamayı güncelle\n",
        "for src, dst in results:\n",
        "    if src and dst:\n",
        "        path_map[src] = dst\n",
        "\n",
        "# DataFrame yollarını yerel diske çevir\n",
        "df_train_m3['path'] = df_train_m3['path'].map(path_map).dropna()\n",
        "df_val_m3['path'] = df_val_m3['path'].map(path_map).dropna()\n",
        "\n",
        "print(\"\\nVeri hazırlığı ve taşıma tamamlandı. Eğitim kodunu çalıştırabilirsin.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtH5wzce3kol",
        "outputId": "be63fb4d-c01d-4b86-ea06-bb97884fec33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 Eğitim Verisi: 420 adet\n",
            "Model 3 Doğrulama Verisi: 5512 adet\n",
            "\n",
            "5827 dosya paralel olarak kopyalanıyor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5827/5827 [04:55<00:00, 19.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Veri hazırlığı ve taşıma tamamlandı. Eğitim kodunu çalıştırabilirsin.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Dataset Sınıfı\n",
        "class MammographyDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        img = cv2.imread(row['path'])\n",
        "\n",
        "        if img is None:\n",
        "            img = np.zeros((224, 224), dtype=np.uint8)\n",
        "        else:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "\n",
        "        # Augmentation Uygulama\n",
        "        aug = row['aug_type']\n",
        "        if aug == 'rot90': img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "        elif aug == 'rot180': img = cv2.rotate(img, cv2.ROTATE_180)\n",
        "        elif aug == 'rot270': img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "\n",
        "        # Normalize ve Tensor\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img = np.expand_dims(img, axis=0) # (1, 224, 224)\n",
        "\n",
        "        return torch.from_numpy(img), torch.tensor(row['binary_label'], dtype=torch.float32)\n",
        "\n",
        "# Swish Aktivasyonu\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x): return x * torch.sigmoid(x)\n",
        "\n",
        "# Model Mimarisi\n",
        "class MammographyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MammographyModel, self).__init__()\n",
        "        # ResNet18 Backbone\n",
        "        self.base = models.resnet18(weights='DEFAULT')\n",
        "        # İlk katman 1 kanal (Grayscale) için\n",
        "        self.base.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.base.fc = nn.Identity()\n",
        "\n",
        "        # Sınıflandırıcı\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            Swish(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base(x)\n",
        "        return self.classifier(features)"
      ],
      "metadata": {
        "id": "VHyFXJzt3qN_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Ayarlar\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "print(f\"Eğitim Cihazı: {device}\")\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(MammographyDataset(df_train_m3), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(MammographyDataset(df_val_m3), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Model Başlatma\n",
        "model = MammographyModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Eğitim Döngüsü\n",
        "best_f1 = 0.0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # --- Train ---\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    val_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {train_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save(model.state_dict(), 'best_model_bi-rads4.pth')\n",
        "        print(\"-> Model Kaydedildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1BFIUL23yIV",
        "outputId": "357a18d7-1b36-4393-f685-2a0d211b2826"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim Cihazı: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 209MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.4631 | Val F1: 0.0000\n",
            "Epoch 2/10 | Loss: 0.2467 | Val F1: 0.0057\n",
            "-> Model Kaydedildi.\n",
            "Epoch 3/10 | Loss: 0.1739 | Val F1: 0.0072\n",
            "-> Model Kaydedildi.\n",
            "Epoch 4/10 | Loss: 0.0980 | Val F1: 0.0112\n",
            "-> Model Kaydedildi.\n",
            "Epoch 5/10 | Loss: 0.0475 | Val F1: 0.0247\n",
            "-> Model Kaydedildi.\n",
            "Epoch 6/10 | Loss: 0.0401 | Val F1: 0.0397\n",
            "-> Model Kaydedildi.\n",
            "Epoch 7/10 | Loss: 0.0505 | Val F1: 0.0206\n",
            "Epoch 8/10 | Loss: 0.0749 | Val F1: 0.0128\n",
            "Epoch 9/10 | Loss: 0.1341 | Val F1: 0.0105\n",
            "Epoch 10/10 | Loss: 0.0685 | Val F1: 0.0800\n",
            "-> Model Kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##sonuçlar çok kötü ama zaten ne bekliyoruz"
      ],
      "metadata": {
        "id": "CvoOCWsO8xkM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNIXMyPQSxLPZTC8rhBCayF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}