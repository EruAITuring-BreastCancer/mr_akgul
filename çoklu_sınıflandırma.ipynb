{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "H100",
      "authorship_tag": "ABX9TyN3smvSS9Y35/UEtlJWovUy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ergul13/mr_akgul/blob/main/%C3%A7oklu_s%C4%B1n%C4%B1fland%C4%B1rma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4j212-QpJX_",
        "outputId": "5114cc3d-8c67-4c0a-b363-f28f5d28c697"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Veri yolları\n",
        "train_csv_path = '/content/drive/MyDrive/SPLIT_DATA/train.csv'\n",
        "val_csv_path = '/content/drive/MyDrive/SPLIT_DATA/val.csv'\n",
        "test_csv_path = '/content/drive/MyDrive/SPLIT_DATA/test.csv'\n",
        "\n",
        "# Verileri yükle\n",
        "df_train = pd.read_csv(train_csv_path)\n",
        "df_val = pd.read_csv(val_csv_path) if os.path.exists(val_csv_path) else pd.DataFrame()\n",
        "df_test = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Renk paleti\n",
        "colors = sns.color_palette('pastel')[0:5]\n",
        "\n",
        "# 1. Genel Dağılım (Eğitim Seti)\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Pasta Grafiği: BI-RADS Dağılımı\n",
        "plt.subplot(1, 3, 1)\n",
        "counts = df_train['label'].value_counts().sort_index()\n",
        "plt.pie(counts, labels=[f'BI-RADS {i}' for i in counts.index], autopct='%1.1f%%', colors=colors, startangle=140)\n",
        "plt.title('Eğitim Seti Sınıf Dağılımı (BI-RADS)')\n",
        "\n",
        "# Çubuk Grafik: Sayısal Dağılım\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.barplot(x=counts.index, y=counts.values, palette='viridis')\n",
        "plt.title('Sınıf Başına Görüntü Sayısı')\n",
        "plt.xlabel('BI-RADS Sınıfları')\n",
        "plt.ylabel('Adet')\n",
        "for i, v in enumerate(counts.values):\n",
        "    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "# Set Dağılımı (Train/Val/Test)\n",
        "plt.subplot(1, 3, 3)\n",
        "sets = ['Eğitim', 'Doğrulama', 'Test']\n",
        "values = [len(df_train), len(df_val), len(df_test)]\n",
        "sns.barplot(x=sets, y=values, palette='rocket')\n",
        "plt.title('Veri Seti Ayrımı')\n",
        "plt.ylabel('Toplam Görüntü')\n",
        "for i, v in enumerate(values):\n",
        "    plt.text(i, v + 100, str(v), ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WW7IC41710LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_augmentation_steps(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # İşlemler\n",
        "    augmentations = {\n",
        "        'Orijinal (224x224)': img,\n",
        "        'Rotate 90': cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),\n",
        "        'Rotate 180': cv2.rotate(img, cv2.ROTATE_180),\n",
        "        'Rotate 270': cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
        "        'Horizontal Flip': cv2.flip(img, 1)\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    plt.suptitle('Model Eğitiminde Uygulanan Veri Artırma (Augmentation) Adımları', fontsize=14, y=1.05)\n",
        "\n",
        "    for i, (name, aug_img) in enumerate(augmentations.items()):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.imshow(aug_img, cmap='gray')\n",
        "        plt.title(name)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# BI-RADS 4 sınıfından bir örnek seçip işlemleri uygula\n",
        "sample_path = df_train[df_train['label'] == 4].iloc[0]['path']\n",
        "visualize_augmentation_steps(sample_path)"
      ],
      "metadata": {
        "id": "vD0IHJUa12ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# CSV yolları\n",
        "train_csv_path = '/content/drive/MyDrive/SPLIT_DATA/train.csv'\n",
        "val_csv_path = '/content/drive/MyDrive/SPLIT_DATA/val.csv' # Validation dosyan varsa\n",
        "\n",
        "# 1. CSV'leri Yükle\n",
        "if os.path.exists(train_csv_path):\n",
        "    df_train = pd.read_csv(train_csv_path)\n",
        "    print(f\"Eğitim listesi yüklendi: {len(df_train)} kayıt\")\n",
        "else:\n",
        "    print(\"HATA: train.csv bulunamadı!\")\n",
        "\n",
        "if os.path.exists(val_csv_path):\n",
        "    df_val = pd.read_csv(val_csv_path)\n",
        "    print(f\"Validation listesi yüklendi: {len(df_val)} kayıt\")\n",
        "else:\n",
        "    print(\"UYARI: val.csv bulunamadı, validation boş geçilecek.\")\n",
        "    df_val = pd.DataFrame()\n",
        "\n",
        "# 2. Model 3 (BI-RADS 4) İçin Veriyi Hazırla\n",
        "# Hedef Sınıf: 4 (Pozitif), Diğerleri: Negatif\n",
        "def prepare_data_from_csv(df, target_class=4):\n",
        "    if len(df) == 0: return df\n",
        "\n",
        "    df_pos = df[df['label'] == target_class].copy()\n",
        "    df_neg = df[df['label'] != target_class].copy()\n",
        "\n",
        "    # Pozitifler için Augmentation işaretlemesi (Sanal Çoğaltma)\n",
        "    augmented_pos = []\n",
        "    for _, row in df_pos.iterrows():\n",
        "        # 4 Farklı varyasyon\n",
        "        augmented_pos.append({'path': row['path'], 'binary_label': 1, 'aug_type': 'original'})\n",
        "        augmented_pos.append({'path': row['path'], 'binary_label': 1, 'aug_type': 'rot90'})\n",
        "        augmented_pos.append({'path': row['path'], 'binary_label': 1, 'aug_type': 'rot180'})\n",
        "        augmented_pos.append({'path': row['path'], 'binary_label': 1, 'aug_type': 'rot270'})\n",
        "\n",
        "    df_pos_aug = pd.DataFrame(augmented_pos)\n",
        "\n",
        "    # Negatiflerden örneklem al (Pozitif sayısının 2 katı kadar)\n",
        "    n_pos = len(df_pos_aug)\n",
        "    n_neg_sample = min(len(df_neg), n_pos * 2)\n",
        "\n",
        "    if n_neg_sample > 0:\n",
        "        df_neg_sampled = resample(df_neg, n_samples=n_neg_sample, replace=False, random_state=42)\n",
        "        neg_data = []\n",
        "        for _, row in df_neg_sampled.iterrows():\n",
        "            neg_data.append({'path': row['path'], 'binary_label': 0, 'aug_type': 'original'})\n",
        "        df_neg_final = pd.DataFrame(neg_data)\n",
        "\n",
        "        # Birleştir\n",
        "        df_final = pd.concat([df_pos_aug, df_neg_final]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "        return df_final\n",
        "    else:\n",
        "        return df_pos_aug\n",
        "\n",
        "# Eğitim verisini hazırla\n",
        "df_model_3 = prepare_data_from_csv(df_train, target_class=4)\n",
        "print(f\"Model 3 Eğitim Verisi Hazır: {len(df_model_3)} adet\")\n",
        "\n",
        "# Validation verisini hazırla (Augmentation yok)\n",
        "val_data_list = []\n",
        "if len(df_val) > 0:\n",
        "    for _, row in df_val.iterrows():\n",
        "        label = 1 if row['label'] == 4 else 0\n",
        "        val_data_list.append({'path': row['path'], 'binary_label': label, 'aug_type': 'original'})\n",
        "    df_val_model3 = pd.DataFrame(val_data_list)\n",
        "    print(f\"Model 3 Validation Verisi Hazır: {len(df_val_model3)} adet\")\n",
        "else:\n",
        "    df_val_model3 = pd.DataFrame()"
      ],
      "metadata": {
        "id": "BAM2t-LWqbvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import copy\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# --- AYARLAR ---\n",
        "BATCH_SIZE = 64 # H100 güçlü olduğu için batch size'ı artırdım\n",
        "EPOCHS = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Çalışma Cihazı: {device}\")\n",
        "\n",
        "# --- SINIF TANIMLARI ---\n",
        "class MammographyDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        img = cv2.imread(row['path'])\n",
        "        if img is None:\n",
        "            img = np.zeros((224, 224), dtype=np.uint8)\n",
        "        else:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "\n",
        "        # Augmentation\n",
        "        aug = row['aug_type']\n",
        "        if aug == 'rot90': img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "        elif aug == 'rot180': img = cv2.rotate(img, cv2.ROTATE_180)\n",
        "        elif aug == 'rot270': img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        return torch.from_numpy(img), torch.tensor(row['binary_label'], dtype=torch.float32)\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x): return x * torch.sigmoid(x)\n",
        "\n",
        "class MammographyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MammographyModel, self).__init__()\n",
        "        self.base = models.resnet18(weights='DEFAULT')\n",
        "        self.base.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.base.fc = nn.Identity()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            Swish(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "    def forward(self, x): return self.classifier(self.base(x))\n",
        "\n",
        "# --- YÜKLEME VE EĞİTİM ---\n",
        "train_loader = DataLoader(MammographyDataset(df_model_3), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(MammographyDataset(df_val_model3), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "model = MammographyModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "print(\"Eğitim Başlıyor...\")\n",
        "best_f1 = 0.0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    train_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            preds = torch.sigmoid(model(inputs)) > 0.5\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    val_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {train_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save(model.state_dict(), 'best_model_3_birads4.pth')\n",
        "        print(\"  -> Model Kaydedildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNKug0PSqmIJ",
        "outputId": "a1c224c8-5160-4b19-ede7-ca3aee2001d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Çalışma Cihazı: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 238MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim Başlıyor...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TaVh1jGWqmoC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}